import torch.nn as nn

# Replace '...' with the appropriate loss function in PyTorch
loss = nn.CrossEntropyLoss()
# Modifying the architecture to be compatible with CE loss
ce_model = nn.Sequential(
    nn.Flatten(),
    nn.Linear(256*256*1, 256),
    nn.ReLU(),
    nn.Linear(256, 2)  # 2 classes: normal and pneumonia
).cuda()
# Convert to PyTorch tensors
x_test = torch.tensor(x_test).float()
y_test = torch.tensor(y_test).long()

# Combine the images and labels into a dataset
test_dataset = TensorDataset(x_test, y_test)

# Create a dataloader to load data in batches. Set batch size to 32.
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)
# Declare the model architecture (using the previously defined model for CE as an example)
model = ce_model

# Load the trained weights
model_path = 'path_to_trained_weights.pth'  # Replace with the actual path
model.load_state_dict(torch.load(model_path))

# Set the model to evaluation mode
model.eval()
test_correct = 0
test_total = 0

with torch.no_grad():
    for images, labels in test_loader:
        
        images = images.cuda()
        images = images / 255.0  # Normalize
        
        labels = labels.cuda()
        
        outputs = model(images)
        
        predicted = outputs.argmax(-1)  # get the index of the class with maximum probability
        
        test_correct += (predicted == labels).sum().item()
        test_total += labels.size(0)

print(f'Test accuracy is {100 * test_correct / test_total}%.')
