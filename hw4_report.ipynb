{"cells":[{"cell_type":"markdown","id":"28784ad1","metadata":{"id":"28784ad1"},"source":["\n","### Model Selection Rationale\n","\n","In the context of transfer learning for biomedical optical imaging, specifically fine-tuning on chest X-ray datasets, the choice of pre-trained models is crucial for achieving high accuracy and efficient computation. Two models stand out in the `torchvision.models` library for this purpose: ResNet50 and MobileNetV2.\n","\n","**ResNet50**: Known for its deep residual learning framework, it addresses the vanishing gradient problem allowing models to be substantially deeper with improved performance. Its \"skip connections\" facilitate the training of much deeper networks by allowing gradients to flow through the network. For tasks requiring high accuracy, ResNet50 is often a go-to model because of its proven track record in image recognition challenges.\n","\n","**MobileNetV2**: Designed for mobile and embedded vision applications, it employs an inverted residual structure with bottleneck layers. It is optimized for speed and efficiency while maintaining reasonable accuracy, making it suitable for applications where computational resources are limited.\n","\n","In summary, ResNet50 is selected for its high accuracy and MobileNetV2 for its balance between efficiency and performance. The computational time for fine-tuning these models on transfer learning tasks is also a significant factor, with ResNet50 requiring more resources due to its complexity, and MobileNetV2 being more resource-friendly.\n"]},{"cell_type":"code","execution_count":17,"id":"9f3dbedf","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9f3dbedf","executionInfo":{"status":"ok","timestamp":1699242453402,"user_tz":-480,"elapsed":4,"user":{"displayName":"John Hsu","userId":"03459311701233526328"}},"outputId":"2738bc0e-6589-4520-f8f5-98bc1edfdc1d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{},"execution_count":17}],"source":["import torchvision.models as models\n","\n","# List all available models in torchvision\n","model_names = [name for name in dir(models) if not name.startswith('_')]\n","\n","# Filter out only the models that have pre-trained versions available\n","pretrained_models = [name for name in model_names if 'pretrained' in dir(getattr(models, name))]\n","\n","pretrained_models"]},{"cell_type":"code","execution_count":null,"id":"79586ab0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"79586ab0","executionInfo":{"status":"ok","timestamp":1699241714057,"user_tz":-480,"elapsed":3894,"user":{"displayName":"John Hsu","userId":"03459311701233526328"}},"outputId":"dee681cf-feae-42af-a92e-d8b23a87781a"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n","100%|██████████| 97.8M/97.8M [00:01<00:00, 65.9MB/s]\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n","100%|██████████| 13.6M/13.6M [00:00<00:00, 49.2MB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["{'resnet': ResNet(\n","   (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","   (relu): ReLU(inplace=True)\n","   (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","   (layer1): Sequential(\n","     (0): Bottleneck(\n","       (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","       (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (relu): ReLU(inplace=True)\n","       (downsample): Sequential(\n","         (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","         (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       )\n","     )\n","     (1): Bottleneck(\n","       (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","       (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (relu): ReLU(inplace=True)\n","     )\n","     (2): Bottleneck(\n","       (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","       (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (relu): ReLU(inplace=True)\n","     )\n","   )\n","   (layer2): Sequential(\n","     (0): Bottleneck(\n","       (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (relu): ReLU(inplace=True)\n","       (downsample): Sequential(\n","         (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","         (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       )\n","     )\n","     (1): Bottleneck(\n","       (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (relu): ReLU(inplace=True)\n","     )\n","     (2): Bottleneck(\n","       (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (relu): ReLU(inplace=True)\n","     )\n","     (3): Bottleneck(\n","       (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","       (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (relu): ReLU(inplace=True)\n","     )\n","   )\n","   (layer3): Sequential(\n","     (0): Bottleneck(\n","       (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (relu): ReLU(inplace=True)\n","       (downsample): Sequential(\n","         (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","         (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       )\n","     )\n","     (1): Bottleneck(\n","       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (relu): ReLU(inplace=True)\n","     )\n","     (2): Bottleneck(\n","       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (relu): ReLU(inplace=True)\n","     )\n","     (3): Bottleneck(\n","       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (relu): ReLU(inplace=True)\n","     )\n","     (4): Bottleneck(\n","       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (relu): ReLU(inplace=True)\n","     )\n","     (5): Bottleneck(\n","       (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","       (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (relu): ReLU(inplace=True)\n","     )\n","   )\n","   (layer4): Sequential(\n","     (0): Bottleneck(\n","       (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","       (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (relu): ReLU(inplace=True)\n","       (downsample): Sequential(\n","         (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","         (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       )\n","     )\n","     (1): Bottleneck(\n","       (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","       (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (relu): ReLU(inplace=True)\n","     )\n","     (2): Bottleneck(\n","       (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","       (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (relu): ReLU(inplace=True)\n","     )\n","   )\n","   (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","   (fc): Linear(in_features=2048, out_features=1000, bias=True)\n"," ),\n"," 'mobilenet': MobileNetV2(\n","   (features): Sequential(\n","     (0): Conv2dNormActivation(\n","       (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","       (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (2): ReLU6(inplace=True)\n","     )\n","     (1): InvertedResidual(\n","       (conv): Sequential(\n","         (0): Conv2dNormActivation(\n","           (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n","           (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","           (2): ReLU6(inplace=True)\n","         )\n","         (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","         (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       )\n","     )\n","     (2): InvertedResidual(\n","       (conv): Sequential(\n","         (0): Conv2dNormActivation(\n","           (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","           (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","           (2): ReLU6(inplace=True)\n","         )\n","         (1): Conv2dNormActivation(\n","           (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n","           (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","           (2): ReLU6(inplace=True)\n","         )\n","         (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","         (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       )\n","     )\n","     (3): InvertedResidual(\n","       (conv): Sequential(\n","         (0): Conv2dNormActivation(\n","           (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","           (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","           (2): ReLU6(inplace=True)\n","         )\n","         (1): Conv2dNormActivation(\n","           (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n","           (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","           (2): ReLU6(inplace=True)\n","         )\n","         (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","         (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       )\n","     )\n","     (4): InvertedResidual(\n","       (conv): Sequential(\n","         (0): Conv2dNormActivation(\n","           (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","           (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","           (2): ReLU6(inplace=True)\n","         )\n","         (1): Conv2dNormActivation(\n","           (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n","           (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","           (2): ReLU6(inplace=True)\n","         )\n","         (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","         (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       )\n","     )\n","     (5): InvertedResidual(\n","       (conv): Sequential(\n","         (0): Conv2dNormActivation(\n","           (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","           (2): ReLU6(inplace=True)\n","         )\n","         (1): Conv2dNormActivation(\n","           (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","           (2): ReLU6(inplace=True)\n","         )\n","         (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","         (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       )\n","     )\n","     (6): InvertedResidual(\n","       (conv): Sequential(\n","         (0): Conv2dNormActivation(\n","           (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","           (2): ReLU6(inplace=True)\n","         )\n","         (1): Conv2dNormActivation(\n","           (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n","           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","           (2): ReLU6(inplace=True)\n","         )\n","         (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","         (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       )\n","     )\n","     (7): InvertedResidual(\n","       (conv): Sequential(\n","         (0): Conv2dNormActivation(\n","           (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","           (2): ReLU6(inplace=True)\n","         )\n","         (1): Conv2dNormActivation(\n","           (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n","           (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","           (2): ReLU6(inplace=True)\n","         )\n","         (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","         (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       )\n","     )\n","     (8): InvertedResidual(\n","       (conv): Sequential(\n","         (0): Conv2dNormActivation(\n","           (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","           (2): ReLU6(inplace=True)\n","         )\n","         (1): Conv2dNormActivation(\n","           (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","           (2): ReLU6(inplace=True)\n","         )\n","         (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","         (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       )\n","     )\n","     (9): InvertedResidual(\n","       (conv): Sequential(\n","         (0): Conv2dNormActivation(\n","           (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","           (2): ReLU6(inplace=True)\n","         )\n","         (1): Conv2dNormActivation(\n","           (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","           (2): ReLU6(inplace=True)\n","         )\n","         (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","         (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       )\n","     )\n","     (10): InvertedResidual(\n","       (conv): Sequential(\n","         (0): Conv2dNormActivation(\n","           (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","           (2): ReLU6(inplace=True)\n","         )\n","         (1): Conv2dNormActivation(\n","           (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","           (2): ReLU6(inplace=True)\n","         )\n","         (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","         (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       )\n","     )\n","     (11): InvertedResidual(\n","       (conv): Sequential(\n","         (0): Conv2dNormActivation(\n","           (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","           (2): ReLU6(inplace=True)\n","         )\n","         (1): Conv2dNormActivation(\n","           (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n","           (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","           (2): ReLU6(inplace=True)\n","         )\n","         (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","         (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       )\n","     )\n","     (12): InvertedResidual(\n","       (conv): Sequential(\n","         (0): Conv2dNormActivation(\n","           (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","           (2): ReLU6(inplace=True)\n","         )\n","         (1): Conv2dNormActivation(\n","           (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","           (2): ReLU6(inplace=True)\n","         )\n","         (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","         (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       )\n","     )\n","     (13): InvertedResidual(\n","       (conv): Sequential(\n","         (0): Conv2dNormActivation(\n","           (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","           (2): ReLU6(inplace=True)\n","         )\n","         (1): Conv2dNormActivation(\n","           (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n","           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","           (2): ReLU6(inplace=True)\n","         )\n","         (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","         (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       )\n","     )\n","     (14): InvertedResidual(\n","       (conv): Sequential(\n","         (0): Conv2dNormActivation(\n","           (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","           (2): ReLU6(inplace=True)\n","         )\n","         (1): Conv2dNormActivation(\n","           (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n","           (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","           (2): ReLU6(inplace=True)\n","         )\n","         (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","         (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       )\n","     )\n","     (15): InvertedResidual(\n","       (conv): Sequential(\n","         (0): Conv2dNormActivation(\n","           (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","           (2): ReLU6(inplace=True)\n","         )\n","         (1): Conv2dNormActivation(\n","           (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","           (2): ReLU6(inplace=True)\n","         )\n","         (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","         (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       )\n","     )\n","     (16): InvertedResidual(\n","       (conv): Sequential(\n","         (0): Conv2dNormActivation(\n","           (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","           (2): ReLU6(inplace=True)\n","         )\n","         (1): Conv2dNormActivation(\n","           (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","           (2): ReLU6(inplace=True)\n","         )\n","         (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","         (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       )\n","     )\n","     (17): InvertedResidual(\n","       (conv): Sequential(\n","         (0): Conv2dNormActivation(\n","           (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","           (2): ReLU6(inplace=True)\n","         )\n","         (1): Conv2dNormActivation(\n","           (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n","           (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","           (2): ReLU6(inplace=True)\n","         )\n","         (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","         (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       )\n","     )\n","     (18): Conv2dNormActivation(\n","       (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","       (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","       (2): ReLU6(inplace=True)\n","     )\n","   )\n","   (classifier): Sequential(\n","     (0): Dropout(p=0.2, inplace=False)\n","     (1): Linear(in_features=1280, out_features=1000, bias=True)\n","   )\n"," )}"]},"metadata":{},"execution_count":2}],"source":["# Selecting two models: one for high accuracy and one for efficiency and speed\n","# For high accuracy, we often choose models like ResNet or DenseNet\n","# For efficiency and speed, we might choose models like MobileNet or SqueezeNet\n","\n","# For this example, let's select ResNet (known for high accuracy) and MobileNet (known for efficiency)\n","\n","selected_models = {\n","    'resnet': getattr(models, 'resnet50')(pretrained=True),\n","    'mobilenet': getattr(models, 'mobilenet_v2')(pretrained=True)\n","}\n","\n","# Save the names and the model objects in a dictionary for later use\n","models_info = {name: model for name, model in selected_models.items()}\n","\n","models_info"]},{"cell_type":"code","execution_count":18,"id":"663f8d4a","metadata":{"id":"663f8d4a","executionInfo":{"status":"ok","timestamp":1699242461948,"user_tz":-480,"elapsed":412,"user":{"displayName":"John Hsu","userId":"03459311701233526328"}}},"outputs":[],"source":["\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","from torch.utils.data import DataLoader\n"]},{"cell_type":"code","execution_count":null,"id":"a2807a1f","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":382},"id":"a2807a1f","executionInfo":{"status":"error","timestamp":1699241735483,"user_tz":-480,"elapsed":288,"user":{"displayName":"John Hsu","userId":"03459311701233526328"}},"outputId":"7eb84d46-56eb-4a6a-97f5-48348bf7741d"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-19e615771f3c>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n\u001b[0m\u001b[1;32m     24\u001b[0m                   for x in ['train', 'val']}\n\u001b[1;32m     25\u001b[0m dataloaders = {x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4)\n","\u001b[0;32m<ipython-input-5-19e615771f3c>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n\u001b[0m\u001b[1;32m     24\u001b[0m                   for x in ['train', 'val']}\n\u001b[1;32m     25\u001b[0m dataloaders = {x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4)\n","\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"]}],"source":["\n","# Assuming that 'data_dir' is the directory that contains the 'train' and 'val' folders of the dataset\n","data_dir = 'path_to_your_data'\n","batch_size = 32\n","num_classes = 2  # For example, normal and pneumonia\n","\n","# Define transforms\n","data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}\n","\n","# Load data\n","image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n","                  for x in ['train', 'val']}\n","dataloaders = {x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4)\n","               for x in ['train', 'val']}\n","\n","dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n"]},{"cell_type":"code","execution_count":null,"id":"71b6fc68","metadata":{"id":"71b6fc68"},"outputs":[],"source":["\n","# Load a pre-trained ResNet50 model\n","model = models.resnet50(pretrained=True)\n","\n","# Replace the last fully connected layer with a new one that matches the number of classes in the new dataset\n","model.fc = nn.Linear(model.fc.in_features, num_classes)\n","\n","# Transfer the model to GPU if available\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n"]},{"cell_type":"code","execution_count":null,"id":"0f4ba0d7","metadata":{"id":"0f4ba0d7"},"outputs":[],"source":["\n","# Define loss function\n","criterion = nn.CrossEntropyLoss()\n","\n","# Define optimizer\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","\n","# Define number of epochs\n","num_epochs = 25\n"]},{"cell_type":"markdown","id":"1413983d","metadata":{"id":"1413983d"},"source":["\n","## Fine-tuning Process and Effectiveness\n","\n","Fine-tuning involves adjusting the pre-trained models to the new dataset, which in this case is a chest X-ray dataset with two classes. The process includes replacing the last layer of the models to fit the number of classes and training the models using the defined loss function and optimizer.\n","\n","### Effectiveness Analysis\n","After training, the models' performance is assessed based on their accuracy and loss on both the training and validation datasets. This provides insights into how well the models have adapted to the new data and whether there are signs of overfitting or underfitting.\n","\n","For a comprehensive analysis, we should also consider:\n","- Training and validation curves over epochs to identify trends.\n","- Possible class imbalances that could affect performance metrics.\n","- The need for further hyperparameter tuning or data augmentation techniques to improve results.\n"]},{"cell_type":"code","execution_count":null,"id":"d602c8e2","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":382},"id":"d602c8e2","executionInfo":{"status":"error","timestamp":1699241749982,"user_tz":-480,"elapsed":649,"user":{"displayName":"John Hsu","userId":"03459311701233526328"}},"outputId":"423374fc-21c5-466c-d0f2-26ca4bff570c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0/24\n","----------\n"]},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-28bcf6b829bd>\u001b[0m in \u001b[0;36m<cell line: 48>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-8-28bcf6b829bd>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# Iterate over data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'dataloaders' is not defined"]}],"source":["\n","# Function to train the model\n","def train_model(model, criterion, optimizer, num_epochs=25):\n","    for epoch in range(num_epochs):\n","        print(f'Epoch {epoch}/{num_epochs - 1}')\n","        print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # Zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # Forward\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    _, preds = torch.max(outputs, 1)\n","                    loss = criterion(outputs, labels)\n","\n","                    # Backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # Statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","            epoch_loss = running_loss / dataset_sizes[phase]\n","            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","\n","            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n","\n","    print('Training complete')\n","    return model\n","\n","# Train the model\n","model = train_model(model, criterion, optimizer, num_epochs=num_epochs)\n"]},{"cell_type":"code","execution_count":null,"id":"5a938e56","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":382},"id":"5a938e56","executionInfo":{"status":"error","timestamp":1699241756585,"user_tz":-480,"elapsed":4,"user":{"displayName":"John Hsu","userId":"03459311701233526328"}},"outputId":"9007260a-a142-491a-e36b-30519fd854e4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0/24\n","----------\n"]},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-6d2695cee63a>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Train the MobileNetV2 model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmobile_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmobile_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmobile_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmobile_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-8-28bcf6b829bd>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# Iterate over data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'dataloaders' is not defined"]}],"source":["\n","# Load a pre-trained MobileNetV2 model\n","mobile_model = models.mobilenet_v2(pretrained=True)\n","\n","# Replace the classifier with a new one that matches the number of classes in the new dataset\n","mobile_model.classifier[1] = nn.Linear(mobile_model.last_channel, num_classes)\n","\n","# Transfer the model to GPU if available\n","mobile_model = mobile_model.to(device)\n","\n","# Define loss function\n","mobile_criterion = nn.CrossEntropyLoss()\n","\n","# Define optimizer for MobileNetV2\n","mobile_optimizer = optim.SGD(mobile_model.parameters(), lr=0.001, momentum=0.9)\n","\n","# Train the MobileNetV2 model\n","mobile_model = train_model(mobile_model, mobile_criterion, mobile_optimizer, num_epochs=num_epochs)\n"]},{"cell_type":"code","execution_count":null,"id":"9e7929c6","metadata":{"id":"9e7929c6"},"outputs":[],"source":["\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","from torch.utils.data import DataLoader\n"]},{"cell_type":"code","execution_count":null,"id":"2bb389b0","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":382},"id":"2bb389b0","executionInfo":{"status":"error","timestamp":1699241764800,"user_tz":-480,"elapsed":322,"user":{"displayName":"John Hsu","userId":"03459311701233526328"}},"outputId":"77e0c3b3-29f6-43b8-9fb9-26ebffb0dca3"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-19e615771f3c>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n\u001b[0m\u001b[1;32m     24\u001b[0m                   for x in ['train', 'val']}\n\u001b[1;32m     25\u001b[0m dataloaders = {x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4)\n","\u001b[0;32m<ipython-input-11-19e615771f3c>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n\u001b[0m\u001b[1;32m     24\u001b[0m                   for x in ['train', 'val']}\n\u001b[1;32m     25\u001b[0m dataloaders = {x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4)\n","\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"]}],"source":["\n","# Assuming that 'data_dir' is the directory that contains the 'train' and 'val' folders of the dataset\n","data_dir = 'path_to_your_data'\n","batch_size = 32\n","num_classes = 2  # For example, normal and pneumonia\n","\n","# Define transforms\n","data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}\n","\n","# Load data\n","image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n","                  for x in ['train', 'val']}\n","dataloaders = {x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4)\n","               for x in ['train', 'val']}\n","\n","dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n"]},{"cell_type":"code","execution_count":null,"id":"1e79d421","metadata":{"id":"1e79d421"},"outputs":[],"source":["\n","# Load a pre-trained ResNet50 model\n","model = models.resnet50(pretrained=True)\n","\n","# Freeze all layers in the network\n","for param in model.parameters():\n","    param.requires_grad = False\n","\n","# Replace the last fully connected layer with a new one that matches the number of classes in the new dataset\n","# Only the parameters of the last layer will be updated during training\n","model.fc = nn.Linear(model.fc.in_features, num_classes)\n","\n","# Transfer the model to GPU if available\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n"]},{"cell_type":"code","execution_count":null,"id":"e7fd16f6","metadata":{"id":"e7fd16f6"},"outputs":[],"source":["\n","# Define loss function\n","criterion = nn.CrossEntropyLoss()\n","\n","# Define optimizer, but only optimize the last layer's parameters\n","optimizer = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)\n","\n","# Define number of epochs\n","num_epochs = 25\n"]},{"cell_type":"markdown","id":"fde2d2df","metadata":{"id":"fde2d2df"},"source":["\n","## Converting Models into Fixed Feature Extractors\n","\n","In this task, we convert pre-trained models into fixed feature extractors by freezing all layers except the last one. This approach allows us to leverage the learned features from the large datasets the models were originally trained on, while only fine-tuning the output layer to our specific task.\n","\n","### Performance Assessment\n","The performance of fixed feature extractors is evaluated based on their accuracy on the validation dataset. Since only the last layer is trained, the process is typically faster and requires less computational resources compared to full model fine-tuning.\n","\n","It's important to note that while fixed feature extractors can be very effective, their performance may also depend on how similar the new task is to the original task the model was trained on.\n"]},{"cell_type":"code","execution_count":null,"id":"a38e0429","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":382},"id":"a38e0429","executionInfo":{"status":"error","timestamp":1699241783101,"user_tz":-480,"elapsed":282,"user":{"displayName":"John Hsu","userId":"03459311701233526328"}},"outputId":"9970785e-222e-4bc3-a6d6-cfed9298040b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0/24\n","----------\n"]},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-28bcf6b829bd>\u001b[0m in \u001b[0;36m<cell line: 48>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-14-28bcf6b829bd>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# Iterate over data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'dataloaders' is not defined"]}],"source":["\n","# Function to train the model\n","def train_model(model, criterion, optimizer, num_epochs=25):\n","    for epoch in range(num_epochs):\n","        print(f'Epoch {epoch}/{num_epochs - 1}')\n","        print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # Zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # Forward\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    _, preds = torch.max(outputs, 1)\n","                    loss = criterion(outputs, labels)\n","\n","                    # Backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # Statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","            epoch_loss = running_loss / dataset_sizes[phase]\n","            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","\n","            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n","\n","    print('Training complete')\n","    return model\n","\n","# Train the model\n","model = train_model(model, criterion, optimizer, num_epochs=num_epochs)\n"]},{"cell_type":"code","execution_count":null,"id":"9e992e5a","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":382},"id":"9e992e5a","executionInfo":{"status":"error","timestamp":1699241789357,"user_tz":-480,"elapsed":391,"user":{"displayName":"John Hsu","userId":"03459311701233526328"}},"outputId":"4f6f63f7-392d-41de-fad9-2413df5c3b04"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0/24\n","----------\n"]},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-be949d007fbb>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Train the MobileNetV2 model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mmobile_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmobile_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmobile_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmobile_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-14-28bcf6b829bd>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# Iterate over data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'dataloaders' is not defined"]}],"source":["\n","# Load a pre-trained MobileNetV2 model\n","mobile_model = models.mobilenet_v2(pretrained=True)\n","\n","# Freeze all layers in the network\n","for param in mobile_model.parameters():\n","    param.requires_grad = False\n","\n","# Replace the classifier with a new one, only the last layer's parameters will be updated during training\n","mobile_model.classifier[1] = nn.Linear(mobile_model.last_channel, num_classes)\n","\n","# Transfer the model to GPU if available\n","mobile_model = mobile_model.to(device)\n","\n","# Define loss function for MobileNetV2\n","mobile_criterion = nn.CrossEntropyLoss()\n","\n","# Define optimizer for MobileNetV2, but only optimize the last layer's parameters\n","mobile_optimizer = optim.SGD(mobile_model.classifier[1].parameters(), lr=0.001, momentum=0.9)\n","\n","# Train the MobileNetV2 model\n","mobile_model = train_model(mobile_model, mobile_criterion, mobile_optimizer, num_epochs=num_epochs)\n"]},{"cell_type":"markdown","id":"5105594c","metadata":{"id":"5105594c"},"source":["\n","## Comparison and Analysis between Fine-Tuning and Feature Extraction\n","\n","The comparison between the fine-tuning approach (Task B) and the use of ConvNets as fixed feature extractors (Task C) highlights the trade-offs between adaptability and computational efficiency.\n","\n","### Fine-Tuning\n","In fine-tuning, the entire network's weights are updated, allowing the model to adjust more finely to the specifics of the new dataset. This often results in higher accuracy but at the cost of increased training time and computational resources.\n","\n","### Fixed Feature Extraction\n","Conversely, using ConvNets as fixed feature extractors speeds up training since only the last layer's weights are updated. This can be more efficient but may yield lower accuracy if the pre-trained features are not as applicable to the new task.\n","\n","### Analysis\n","The actual results will depend on the specific characteristics of the datasets and the nature of the tasks. For instance, if the new task is significantly different from the original training data, fine-tuning may provide substantial benefits. However, if the tasks are similar, feature extraction might suffice with much less computational effort.\n"]},{"cell_type":"code","execution_count":null,"id":"73e83d48","metadata":{"id":"73e83d48"},"outputs":[],"source":["\n","# Code to load actual results from Task B and Task C would go here.\n","# For the purposes of this notebook, we will use the placeholder dictionaries as an example.\n","\n","results_task_b = {\n","    'resnet': {'train_acc': 0.95, 'val_acc': 0.85},\n","    'mobilenet': {'train_acc': 0.90, 'val_acc': 0.80}\n","}\n","\n","results_task_c = {\n","    'resnet': {'train_acc': 0.90, 'val_acc': 0.80},\n","    'mobilenet': {'train_acc': 0.85, 'val_acc': 0.75}\n","}\n","\n","def compare_results(results_task_b, results_task_c):\n","    for model_name in results_task_b.keys():\n","        print(f\"Model: {model_name}\")\n","        b_train_acc = results_task_b[model_name]['train_acc']\n","        b_val_acc = results_task_b[model_name]['val_acc']\n","        c_train_acc = results_task_c[model_name]['train_acc']\n","        c_val_acc = results_task_c[model_name]['val_acc']\n","\n","        print(f\"Fine-tuning - Training Accuracy: {b_train_acc}, Validation Accuracy: {b_val_acc}\")\n","        print(f\"Feature Extraction - Training Accuracy: {c_train_acc}, Validation Accuracy: {c_val_acc}\")\n","        print()\n","\n","# Run the comparison function\n","compare_results(results_task_b, results_task_c)\n"]},{"cell_type":"markdown","id":"240f134b","metadata":{"id":"240f134b"},"source":["\n","## Test Dataset Performance Analysis\n","\n","Improving the performance on the test dataset can be challenging due to various factors such as overfitting, data imbalance, or the inherent difficulty of the task. This analysis aims to identify potential areas for improvement by examining the test results.\n","\n","### Challenges\n","- **Overfitting**: The model may perform well on the training data but fails to generalize to unseen data.\n","- **Data Imbalance**: Certain classes may be underrepresented, leading to poor performance on those classes.\n","- **Data Quality**: Issues with the data itself, such as noise or errors in labeling, can adversely affect performance.\n","- **Model Capacity**: The model might be too simple to capture the complexity of the data or too complex, leading to overfitting.\n","\n","### Analysis Process\n","- Review the confusion matrix to understand the misclassifications.\n","- Consider class-specific performance to identify if certain classes are problematic.\n","- Examine the errors made by the model to look for patterns or common issues.\n"]},{"cell_type":"markdown","id":"2bde018a","metadata":{"id":"2bde018a"},"source":["\n","# Code to load actual test results from Task B and Task C would go here.\n","# For the purposes of this notebook, we will use the placeholder dictionary as an example.\n","\n","test_results = {\n","    'resnet': {'test_acc': 0.80},\n","    'mobilenet': {'test_acc': 0.75}\n","}\n","\n","def analyze_test_performance(test_results):\n","    # Placeholder for the analysis process.\n","    for model_name, metrics in test_results.items():\n","        test_acc = metrics['test_acc']\n","        print(f\"Model: {model_name}, Test Accuracy: {test_acc}\")\n","        # Here you would add your analysis code, which might involve examining the errors made by the model,\n","        # looking at misclassified examples, or calculating additional performance metrics.\n","\n","# Run the analysis function\n","analyze_test_performance(test_results)\n"]},{"cell_type":"code","execution_count":null,"id":"e2fe8d86","metadata":{"id":"e2fe8d86"},"outputs":[],"source":["\n","# Placeholder code for test dataset performance analysis\n","# In a real-world scenario, this code would load the test dataset results,\n","# perform the analysis, and potentially make use of libraries like scikit-learn for metrics and confusion matrix.\n","\n","test_results = {'resnet': {'test_acc': 0.80}, 'mobilenet': {'test_acc': 0.75}}\n","\n","def analyze_test_performance(test_results):\n","    for model_name, metrics in test_results.items():\n","        test_accuracy = metrics['test_acc']\n","        print(f\"Model: {model_name}, Test Accuracy: {test_accuracy}\")\n","        # Placeholder for the analysis process. This might include:\n","        # - Calculating and reviewing the confusion matrix.\n","        # - Checking for overfitting/underfitting using training/validation curves.\n","        # - Considering class imbalance and its impact on metrics.\n","        # - Additional preprocessing or data augmentation techniques.\n","        # - Exploring different model architectures or hyperparameter tuning.\n","        # Code for these analyses would go here.\n","\n","# Run the analysis function\n","analyze_test_performance(test_results)\n"]}],"metadata":{"colab":{"provenance":[]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}